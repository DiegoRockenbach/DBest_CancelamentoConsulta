/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package ibd.query;

import ibd.query.binaryop.BinaryOperation;
import ibd.query.binaryop.join.Join;
import ibd.query.lookup.ColumnElement;
import ibd.query.lookup.CompositeLookupFilter;
import ibd.query.lookup.Element;
import ibd.query.lookup.LookupFilter;
import ibd.query.lookup.NoLookupFilter;
import ibd.query.lookup.ReferencedElement;
import ibd.query.lookup.SingleColumnLookupFilter;
import ibd.query.lookup.TwoColumnsLookupFilter;
import ibd.table.prototype.column.Column;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Stack;

/**
 * An operation in this context is defined as a data transformation step within
 * a tree structure, which serves as a query execution plan. Each node within
 * the tree, representing an operation, plays a specific role in the process of
 * data access and transformation:
 *
 * - Source operations: These are leaf nodes that directly interact with data
 * sources, initiating data flow. 
 * - Unary operations: Nodes that perform transformations using data from a 
 * single preceding operation. 
 * - Binary operations: Nodes that manipulate data received from two preceding
 * operations.
 *
 * Data flows from the leaf nodes to the root, with each node processing
 * incoming tuples from underlying operations and producing new tuples as a
 * result of its transformation. The leaf nodes, being source operations, are
 * the entry points for data sources. The root node represents the entire query,
 * aggregating and finalizing the data transformation process.
 *
 * Regarding tuple formation: 
 * - Source operations produce tuples consisting of a  * single row from their 
 * respective data sources. 
 * - Unary operations produce tuples that contain the same number of rows as 
 * the tuples provided by the underlying operation. 
 * - Binary operations, such as joins, produce tuples where the number of rows 
 * is the sum of the rows from the two input tuples provided by the connected children.
 *
 * Queries can be executed at any node; which redirects the request to the
 * relevant operations below it, leveraging the hierarchical structure to
 * execute the query across the various transformation stages.
 *
 * @author Sergio
 */
public abstract class Operation {

    /**
     * the data sources accessed directly or indirectly by this operation. This
     * information is useful to identify which row from a returning tuple comes
     * from a specific data source. Given the refered data source name, the row
     * can be located and used by the transformation process.
     */
    protected ReferedDataSource[] dataSources;

    /**
     * The `processedOperations` variable contains a list of all operations that
     * execute prior to the current operation. This list provides access to all
     * the tuples and their respective rows generated by these preceding
     * operations. Such accessibility enables the use of reference columns,
     * analogous to correlated variables in SQL. In SQL, these variables are
     * often employed in filters within subqueries. Similarly, in our query
     * engine, this feature allows the creation of dynamic filters that operate
     * on data produced by the already executed operations, enabling complex
     * data querying scenarios and deeper data interaction across different
     * stages of the query execution plan.
     */
    protected List<Operation> processedOperations = null;

    /**
     * the parent operation, if one exists
     */
    protected Operation parentOperation;

    /**
     * the operation is ready to call the prepare method. It needs to have the data sources
     * set immediately prior to calling the prepare method.
     */
    protected boolean isReady = false;

    /**
     * The index of the first tuple to retrieve. Must be a non-negative integer.
     * All tuples before the index are computed but not retrieved.
     */
    protected int startingTuple = -1;

    /**
     * The number of tuples to read from the starting tuple. Must be a positive
     * integer.
     */
    protected int tuplesToRead = -1;

    /**
     * Indicates if this operator has filters delegated from its parent that
     * need to be performed.
     */
    protected boolean hasDelegatedFilters = true;

    private boolean runFromHere = false;

    /**
     * Sets information regarding the tuples that need to be retrieved, based on
     * the index of the computed tuples
     *
     * @param startingTuple: The index of the first tuple to retrieve. Must be a
     * non-negative integer.
     * @param tuplesToRead The number of tuples to read from the starting tuple.
     * Must be a positive integer.
     */
    public void setPageInfo(int startingTuple, int tuplesToRead) {
        this.startingTuple = startingTuple;
        this.tuplesToRead = tuplesToRead;
    }

    /**
     * @return The index of the first tuple to retrieve.
     */
    public int getStartingTuple() {
        return startingTuple;
    }

    /**
     * @return The number of tuples to read from the starting tuple.
     */
    public int getTuplesToRead() {
        return tuplesToRead;
    }

    /**
     * @return the data sources accessed directly or indirectly by this
     * operation
     * @throws Exception
     */
    public ReferedDataSource[] getDataSources() throws Exception {
        return dataSources;
    }

    /**
     * Prepares this operation for query answering performing one-time setup
     * commands. The preparation involves, among others: 
     * - setting up static variables;
     * - setting array indexes to row columns; 
     * - opening data sources, if any;
     * - preparing the underlying operations, if any.
     *
     * @throws Exception
     */
    public void prepare() throws Exception {
        //if the query starts with this operation, the filters from the parent
        //must be ignored
        if (!runFromHere) {
            checkFilters();
        }
        
       
    }

    /**
     *
     * @return a boolean indicating if this operation needs to perform filters
     * that come from its parent.
     */
    public boolean hasDelegatedfilters() {
        return hasDelegatedFilters;
    }

    /**
     * Sets the hasDelegatedFilters variable. The variable is true if this
     * operator needs to perform filters that come from its parent
     *
     * @throws Exception
     */
    private void checkFilters() throws Exception {

        hasDelegatedFilters = false;
        if (parentOperation == null) {
            return;
        }

        //if the parent operator has non empty filters, we initially set it to true
        if (!(parentOperation.getFilters() instanceof NoLookupFilter)) {
            hasDelegatedFilters = true;
        }
        if (parentOperation instanceof BinaryOperation) {
            BinaryOperation bop = (BinaryOperation) parentOperation;
            if (bop.useLeftSideLookups()) {
                //the parent binary operator delegates filters to the right side, but this operator is not on the right side
                if (bop.getLeftOperation().equals(this)) {
                    hasDelegatedFilters = false;
                }
            } else {
                //the parent binary operator does not delegates filters to the right side
                //TO DO: check if this works
                hasDelegatedFilters = false;
            }

        }

//        if (hasDelegatedFilters) {
//            setTupleIndex(parentOperation.getFilters());
//        }

    }

    /*
    * Some filters refer to colum value comparisons. For those filters a tuple index is required to 
    * locate the tuple whose column will be compared.
    * The tuple index is set based on the table name information retrieved from the filter.
     */
    private void setTupleIndex(LookupFilter filter) throws Exception {
        if (filter instanceof CompositeLookupFilter) {
            setTupleIndex((CompositeLookupFilter) filter);

        } else if (filter instanceof SingleColumnLookupFilter) {
            setTupleIndex((SingleColumnLookupFilter) filter);
        } else if (filter instanceof TwoColumnsLookupFilter) {
            setTupleIndex((TwoColumnsLookupFilter) filter);
        }
    }

    //sets the tuple indexes for all parts of this composite filter
    private void setTupleIndex(CompositeLookupFilter filter) throws Exception {
        for (LookupFilter filter1 : filter.getFilters()) {
            setTupleIndex(filter1);
        }
    }

    private ColumnElement setTupleIndex(ColumnElement elem) throws Exception{
        try {
        setColumnLocation(elem.getColumnDescriptor());
        }
        catch(Exception e){
            boolean found = setColumnLocationFromProcessedOperations(elem.getColumnDescriptor());
            if (found){
                return new ReferencedElement(elem.getColumnDescriptor());
            }
            else throw new Exception("Error in operation "+this+".\nColumn " + elem.getColumnDescriptor().getColumnName()+" not found.");
        
        }
        return null;
    }
    
    //sets the tuple index for this single column filter
    private void setTupleIndex(SingleColumnLookupFilter filter) throws Exception{

            //sets  the tuple index of the column to be filtered.
            if (filter.getFirstElement() instanceof ColumnElement){
            ColumnElement colElem = (ColumnElement)filter.getFirstElement();
            ColumnElement newElem = setTupleIndex(colElem);
            if (newElem!=null)
                filter.setFirstElement(newElem);
            }
            //sets the tuple location of the column to be used as a reference value, if necessary
            //sets the tuple location of the column to be used as a reference value, if necessary
            
            if (filter.getSecondElement() instanceof ColumnElement){
            ColumnElement colElem = (ColumnElement) filter.getSecondElement();
            ColumnElement newElem = setTupleIndex(colElem);
            if (newElem!=null)
                filter.setSecondElement(newElem);
            }
        
    }

    private void setTupleIndex(TwoColumnsLookupFilter filter) {
        try {

            //sets the tuple index of the left-side comparison column 
            setColumnLocation(filter.getLeftColumn());
            //filter.setLeftTupleIndex(tupleIndex);

            //sets the tuple index of the right-side comparison column
            setColumnLocation(filter.getRightColumn());
            //filter.setRightTupleIndex(tupleIndex);

        } catch (Exception ex) {
        }
    }

    
    /**
     *
     * @return
     */
    public boolean canProcessDelegatedFilters() {
        return false;
    }
    
    /**
     *
     * @return
     */
    public LookupFilter getDelegatedFilters() {
        if (hasDelegatedFilters) {
            return parentOperation.getFilters();
        }
        return new NoLookupFilter();
    }

    /**
     * Retrieves the filters generated by this operation. Operations that contain 
     * filters (such as 'Filter' and 'NestedLoopJoin') should try to delegated the 
     * execution to one of its direct underlying operations. The operation only 
     * processed its own filters if the underlying operation is unable to do it 
     * efficiently. This setup allows for modular and efficient filtering mechanisms 
     * where processing is delegated to appropriate subcomponents of the query plan.
     *
     * @return the filters.
     */
    public LookupFilter getFilters() {
        return new NoLookupFilter();
    }

    ;
    
    

    /**
     * Sets the parent operation
     *
     * @param op
     */
    public void setParentOperation(Operation op) {
        parentOperation = op;
    }

    /**
     * @return the parent operation
     */
    public Operation getParentOperation() {
        return parentOperation;
    }

    /**
     * Returns the index of the row refered by an alias. if no alias is
     * provided, the first row is selected (index 0)
     *
     * @param tableName the alias of the table
     * @return the found index or -1 if no index was found
     * @throws Exception
     */
    public int getRowIndex(String tableName) throws Exception {
        if (tableName == null) {
            return 0;
        } else {
            ReferedDataSource[] dataSources_ = getDataSources();
            for (int i = 0; i < dataSources_.length; i++) {
                if (dataSources_[i].alias.equals(tableName)) {
                    return i;
                }

            }
        }
        return -1;
    }

    /**
     * Returns the data source refered by an alias.
     *
     * @param tableName the alias of the table
     * @return the data source refered by the alias
     * @throws Exception
     */
    public ReferedDataSource getDataSource(String tableName) throws Exception {
        if (tableName == null) {
            return null;
        } else {
            ReferedDataSource[] dataSources_ = getDataSources();
            for (int i = 0; i < dataSources_.length; i++) {
                if (dataSources_[i].alias.equals(tableName)) {
                    return dataSources_[i];
                }

            }
        }
        return null;
    }

    /**
     * @return the size of a tuple generated by this operation
     * @throws Exception
     */
    public int getTupleSize() throws Exception {
        int size = 0;
        for (ReferedDataSource referedDataSource : getDataSources()) {
            size += referedDataSource.prototype.getSizeInBytes();
        }
        return size;
    }

//    public int getColumnIndex(int rowIndex, String Column) throws Exception {
//
//        ReferedDataSource[] dataSources_ = getDataSources();
//        Column col = dataSources_[rowIndex].prototype.getColumn(Column);
//        return col.index;
//    }
    /**
     * Sets the array indexes that identify the most recent value of a specified
     * column, taking into account tuples from previously processed operations.
     * This method operates in three distinct steps:
     *
     * 1. **Locate Operation Index**: Identify the index of the processed
     * operation within the hierarchy that contains the relevant data source.
     * This indirectly leads to the most recent tuple generated by this
     * operation.
     *
     * 2. **Locate Data Source Index**: The identified tuple is composed of
     * rows, each originating from a data source. The second step determines the
     * index of the proper data source, which indirectly leads to the specific
     * row from which the data originates.
     *
     * 3. **Locate Column Index**: The identified data source is composed of
     * columns. The third step finds the index of the proper column within the
     * data source. This index indirectly corresponds to the specific column
     * value (field) within the row.
     *
     * With these three indexes (operation, data source, and column) we can
     * accurately locate the desired column value during query execution,
     * ensuring that the most recent data from an already processed operation is
     * accessed.
     *
     * @param columnDescriptor
     * @throws Exception
     */
    public boolean setColumnLocationFromProcessedOperations(ColumnDescriptor columnDescriptor) throws Exception {

        for (int i = 0; i < processedOperations.size(); i++) {
            Operation processedOperation = processedOperations.get(i);
            processedOperation.setColumnLocation(columnDescriptor);
            ColumnLocation auxColumnLocation = columnDescriptor.getColumnLocation();
            if (auxColumnLocation != null) {
                auxColumnLocation.tupleIndex = i;
                return true;
            }
        }
        return false;
    }

    /**
     * Sets the array indexes that identify the most recent value of a specified
     * column, taking into account data from the tuple under processing by this
     * operation. This method operates in two distinct steps:
     *
     * 1. **Locate Data Source Index**: The tuple under processing is composed
     * of rows, each originating from a data source. The first step determines
     * the index of the proper data source, which indirectly leads to the
     * specific row from which the data originates.
     *
     * 2. **Locate Column Index**: The identified data source is composed of
     * columns. The second step finds the index of the proper column within the
     * data source. This index indirectly corresponds to the specific column
     * value (field) within the row.
     *
     * With these two indexes (data source and column) we can accurately locate
     * the desired column value during query execution, ensuring that the most
     * recent data is accessed.
     *
     * @param columnDescriptor
     * @throws Exception
     */
    public void setColumnLocation(ColumnDescriptor columnDescriptor) throws Exception {

        ColumnLocation colLoc = new ColumnLocation();

        if (columnDescriptor.getTableName() == null) {
            colLoc.tupleIndex = 0;
            colLoc.rowIndex = 0;
            ReferedDataSource[] dataSources_ = getDataSources();
            Column col = dataSources_[0].prototype.getColumn(columnDescriptor.getColumnName());
            if (col==null)
                throw new Exception("Error in operation "+this+".\nColumn " + columnDescriptor.getColumnName()+" not found.");
            colLoc.colIndex = col.index;
            columnDescriptor.setColumnLocation(colLoc);
        } else {
            int rowIndex = getRowIndex(columnDescriptor.getTableName());
            if (rowIndex != -1) {
                Column col = getDataSources()[rowIndex].prototype.getColumn(columnDescriptor.getColumnName());
                if (col==null)
                    throw new Exception("Error in operation "+this+".\nColumn " + columnDescriptor.getColumnName()+" not found.");
                colLoc.rowIndex = rowIndex;
                colLoc.colIndex = col.index;
                columnDescriptor.setColumnLocation(colLoc);
            }
            else throw new Exception("Error in operation "+this+".\nTable " + columnDescriptor.getTableName()+" not found.");
        }

    }

    /**
     * sets information about the data sources that are directly or indirectly
     * accessed by this operation. The information includes the source alias and
     * schema. TO be used during the preparation of the execution tree.
     *
     * @throws Exception
     */
    public abstract void setDataSourcesInfo() throws Exception;

    /**
     * Sets the list of operations that processes tuples before
     * this operation executes. Columns from these operations can be used in 
     * referenced filters.
     */
    public void setProcessedOperations() {

        processedOperations = new ArrayList();

        Operation parent = getParentOperation();
        if (parent != null && parent.processedOperations != null && !runFromHere) {
            List<Operation> processedOperations_ = parent.processedOperations;
            //the processing operations contains all processing operations of the parent node
            processedOperations.addAll(processedOperations_);
            if (parent instanceof Join) {
                Join join = (Join) parent;

                //if this is the right side of a nested loop join, the processing operations also contains the tuple that was produced by the left-side operation. 
                if (join.useLeftSideLookups() && join.getRightOperation().equals(this)) {
                    processedOperations.add(join.getLeftOperation());
                }
            }
        }
    }

    /**
     * Runs a query, using this operation to transform data and produce
     * resulting tuples.
     *
     * This method must be implemented by operations that actually produce
     * tuples as a result of their processing. Extensions can benefit from the
     * OperationIterator class that contains an overall code strucure already
     * defined, leaving only the tuple generation part to be implemented.
     *
     * @param processedTuples the tuples that come from operations already
     * processed. The rows from these tuples can be used by the unprocessed
     * operations, like for referenced filtering.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return an iterator containing the tuples that answer the query.
     */
    protected abstract Iterator<Tuple> lookUp_(List<Tuple> processedTuples, boolean withFilterDelegation);

    /**
     * Runs a query, using this operation to transform data and produce
     * resulting tuples. Avoid calling this method directly, as it depends on
     * some preparation settings. Use the method 'run' instead.
     *
     * @param processedTuples the tuples that come from operations already
     * processed. The rows from these tuples can be used by the unprocessed
     * operations, like for referenced filtering.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return an iterator containing the tuples that answer the query.
     */
    public Iterator<Tuple> lookUp(List<Tuple> processedTuples, boolean withFilterDelegation) {
        if (tuplesToRead != -1 && startingTuple != -1) {
            return pagedLookUp(processedTuples, withFilterDelegation, startingTuple, tuplesToRead);
        } else {
            return lookUp_(processedTuples, withFilterDelegation);
        }
    }

    /**
     * Runs a query, retrieving only the tuples that match the paging parameters
     * (startingTuple and tuplesToRead).
     *
     * @param processedTuples the tuples that come from operations already
     * processed.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @param startingTuple The index of the first tuple to retrieve. Must be a
     * non-negative integer.
     * @param tuplesToRead The number of tuples to read from the starting tuple.
     * Must be a positive integer.
     * @return an iterator containing the tuples that answer the query.
     */
    protected Iterator<Tuple> pagedLookUp(List<Tuple> processedTuples, boolean withFilterDelegation, int startingTuple, int tuplesToRead) {
        return new PagedOperationIterator(lookUp_(processedTuples, withFilterDelegation), startingTuple, tuplesToRead);
    }

    /**
     * Verifies if this operation produces resulting tuples.
     *
     * @param processedTuples the tuples that come from operations already
     * processed. The rows from these tuples can be used by the unprocessed
     * operations, like for referenced filtering.
     * @param withFilterDelegation indicates if the filters created by the
     * parent operation need to be processed. Set this to false if the execution
     * starts from this operation.
     * @return true if at least one tuple exists as a result of this operation.
     */
    public boolean exists(List<Tuple> processedTuples, boolean withFilterDelegation) {
        Iterator<Tuple> iterator = pagedLookUp(processedTuples, withFilterDelegation, 0, 1);
        return iterator.hasNext();
    }

    /*************************************************************************
     * Code added for compatibility reasons with the DBest query execution tool.
     */
    Iterator<Tuple> currentRun;

    public void open() throws Exception {
        currentRun = run();
    }

    public Tuple next() {
        return currentRun.next();
    }

    public boolean hasNext() {
        return currentRun.hasNext();
    }

    /**************************************************************************/
    
    protected List<Operation> childOperations = new ArrayList();
    public List<Operation> getChildOperations(){
        return childOperations;
    }
    
    protected void prepareFromTopDown() throws Exception{
         setTupleIndex(getFilters());
    }
    
    private void prepareAllFromTopDown() throws Exception{
    Stack<Operation> stack = new Stack<>();
        Operation current = this;

        while (current != null || !stack.isEmpty()) {
            // Traverse to the leftmost node
            while (current != null) {
                stack.push(current);
                List<Operation> children = current.getChildOperations();
                current = (children != null && !children.isEmpty()) ? children.get(0) : null;
            }

            // Process the node
            current = stack.pop();
            current.prepareFromTopDown();

            // Move to the right child, if any
            List<Operation> children = current.getChildOperations();
            current = (children != null && children.size() > 1) ? children.get(1) : null;
        }
    }
    
    //this replaces the recursive method where the operations are responsible for calling setDatSOurces for their child operations
    //not yet in use
    public void prepareAllDataSources() throws Exception {

        Stack<Operation> stack = new Stack<>();
        Stack<Operation> processedStack = new Stack<>();
        stack.push(this);

        // Post-order traversal using two stacks
        while (!stack.isEmpty()) {
            Operation current = stack.pop();
            processedStack.push(current);

            // Push children onto the stack
            List<Operation> children = current.getChildOperations();
            if (children != null) {
                for (Operation child : children) {
                    stack.push(child);
                }
            }
        }

        // Process nodes in post-order
        while (!processedStack.isEmpty()) {
            processedStack.pop().setDataSourcesInfo();
        }
    }
    
    /**
     * Used for compatibility reasons with DBest. 
     *
     * @return a map containing the source alias and its columns for all information
     * returned by a tuple.
     */
    public abstract Map<String, List<String>> getContentInfo();

    /**
     * Runs a query, using the tree below this operation to transform data and
     * produce resulting tuples.
     *
     * @return an iterator containing the tuples that answer the query
     * @throws java.lang.Exception
     */
    public Iterator<Tuple> run() throws Exception {
        try{
        runFromHere = true;
        hasDelegatedFilters = false;
        //sets information from the data sources that are important during query execution
        setDataSourcesInfo();
        
        setProcessedOperations();

        prepareAllFromTopDown();
        //prepares the operations from the query tree
        prepare();
        }
        catch(Exception ex){
            runFromHere = false;
            throw ex;
        }
        
        runFromHere = false;

        //runs the query using with an empty list of processed operations and no delegated filters .
        return lookUp(new ArrayList(), false);
    }

    /**
     * Cleans up resources, if necessary, for the whole hierarchy starting from
     * this operation.
     *
     * @throws Exception
     */
    public abstract void close() throws Exception;

}
